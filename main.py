# main.py
from src.reporter.generate_reports import generate_monthly_report
from src.preprocessor.core import preprocess_campaign_data
from src.analyser.core import analyze_campaign_data_from_db
from src.database.save import save_to_postgres  # ðŸš€ NEW import
from sqlalchemy import create_engine
from datetime import datetime, timedelta
from src.reporter.generate_reports import generate_weekly_report
import os
import pandas as pd

def main():
    input_path = "local_run/input" # "/opt/ml/processing/input" # "local_run/input"
    output_path = "local_run/output" # "/opt/ml/processing/output" # "local_run/output"
    #img_output_dir = os.path.join(output_path, 'figures')

    print(f"ðŸš€ Starting analysis. Reading files from {input_path}")

    # Load all CSV files and concatenate them
    input_files = [f for f in os.listdir(input_path) if f.endswith('.csv')]
    if not input_files:
        raise FileNotFoundError("No CSV files found in the input path.")

    print(f"ðŸ“¦ Found {len(input_files)} CSV files. Loading and combining them...")

    # Create a list to hold all DataFrames 
    dfs = []

    for file in input_files:
        file_path = os.path.join(input_path, file)
        df = pd.read_csv(file_path)
        dfs.append(df)
        print(f"   âœ… Loaded {file} with {len(df)} rows")

    # Concatenate all DataFrames
    combined_df = pd.concat(dfs, ignore_index=True)
    print(f"ðŸŽ‰ Successfully combined all files. Total rows: {len(combined_df)}")

    # Now use combined_df for your further processing

    # Run preprocessing
    print("ðŸ§¼ Preprocessing the data...")
    df = preprocess_campaign_data(combined_df, output_path)

    # Save to PostgreSQL
    print("ðŸ’¾ Saving to database...")
    save_to_postgres(df)

    # Run analysis
    print("ðŸ“Š Analyzing the campaign data...")
    
    # Connect to DB
    engine = create_engine("postgresql+psycopg2://keith:ArrestedDevelopment@metaad-campaign-db.cl4qg28aywnx.eu-north-1.rds.amazonaws.com:5432/metaads")

    # Run analysis from DB
    analyze_campaign_data_from_db(engine, output_path)

    #output_report_path = os.path.join(output_path, 'analysis_report.txt')
    #analyze_campaign_data(df, output_path, output_report_path, img_output_dir)

    print("âœ… Analysis complete!")

    # Generate monthly and weekly reports
    print("ðŸ“… Generating monthly reports...")
    generate_monthly_report(engine, "reports/monthly", 2025, 3)

    # Generate weekly report for the last Sunday
    # Assuming the last Sunday is the last day of the previous week
    today = datetime.today()
    last_sunday = today - timedelta(days=today.weekday() + 1)  # Sunday of the previous week
    print("ðŸ“… Generating weekly reports...")
    generate_weekly_report(engine, "reports/weekly", last_sunday)

if __name__ == "__main__":
    main()
